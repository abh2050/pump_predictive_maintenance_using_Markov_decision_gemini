{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f368c9c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /opt/anaconda3/envs/dogo/lib/python3.13/site-packages (1.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r6/b87zwk157sz4fy3q2qlsmrp00000gn/T/ipykernel_15482/43154525.py:16: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  \"timestamp\": pd.date_range(start=\"2025-01-01\", periods=time_steps, freq=\"H\"),\n"
     ]
    }
   ],
   "source": [
    "%pip install python-dotenv\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "# Set the environment variable for the CSV file path\n",
    "\n",
    "# 1. Generate Synthetic Time Series Data\n",
    "def generate_synthetic_pump_data(filename=\"synthetic_pump_data.csv\", time_steps=100000):\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Use a smaller frequency (hours instead of days) to avoid datetime overflow\n",
    "    data = {\n",
    "        \"timestamp\": pd.date_range(start=\"2025-01-01\", periods=time_steps, freq=\"H\"),\n",
    "        \"vibration\": np.random.normal(loc=0.2, scale=0.05, size=time_steps),\n",
    "        \"temperature\": np.random.normal(loc=60, scale=1.0, size=time_steps),\n",
    "        \"pressure\": np.random.normal(loc=30, scale=2.0, size=time_steps),\n",
    "        \"flow_rate\": np.random.normal(loc=100, scale=10.0, size=time_steps),\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Adjust anomaly indices for hourly data\n",
    "    # Inject a variety of anomalies\n",
    "    \n",
    "    # 1. Isolated severe anomalies (major equipment failures)\n",
    "    severe_anomaly_indices = [60, 70, 85, 1000, 5000, 15000, 25000, 40000, 60000, 85000]\n",
    "    # Make sure indices are within range\n",
    "    severe_anomaly_indices = [i for i in severe_anomaly_indices if i < time_steps]\n",
    "    df.loc[severe_anomaly_indices, \"vibration\"] += 0.5\n",
    "    df.loc[severe_anomaly_indices, \"temperature\"] += 5\n",
    "    df.loc[severe_anomaly_indices, \"pressure\"] -= 10\n",
    "    df.loc[severe_anomaly_indices, \"flow_rate\"] -= 20\n",
    "    \n",
    "    # 2. Gradual degradation patterns (equipment wearing out)\n",
    "    degradation_start_indices = [2000, 30000, 70000]\n",
    "    degradation_start_indices = [i for i in degradation_start_indices if i < time_steps]\n",
    "    \n",
    "    for start_idx in degradation_start_indices:\n",
    "        if start_idx + 100 <= time_steps:\n",
    "            for i in range(100):\n",
    "                idx = start_idx + i\n",
    "                # Progressive degradation over 100 time units\n",
    "                df.loc[idx, \"vibration\"] += 0.005 * i\n",
    "                df.loc[idx, \"temperature\"] += 0.05 * i\n",
    "                df.loc[idx, \"pressure\"] -= 0.1 * i\n",
    "    \n",
    "    # 3. Seasonal patterns (adapted for hourly data)\n",
    "    for i in range(0, time_steps, 24*30):  # Approximately monthly patterns\n",
    "        if i + 24*7 <= time_steps:  # 7 days of higher temperature\n",
    "            summer_indices = range(i, i + 24*7)  # A week of higher temps\n",
    "            df.loc[summer_indices, \"temperature\"] += 2.5\n",
    "    \n",
    "    # 4. Random minor anomalies (normal operational variations)\n",
    "    num_minor_anomalies = min(time_steps // 10, 5000)  # Scale with dataset size, cap at 5000\n",
    "    minor_anomaly_indices = np.random.choice(time_steps, size=num_minor_anomalies, replace=False)\n",
    "    df.loc[minor_anomaly_indices, \"vibration\"] += np.random.normal(0.1, 0.05, size=num_minor_anomalies)\n",
    "    df.loc[minor_anomaly_indices, \"temperature\"] += np.random.normal(1.0, 0.5, size=num_minor_anomalies)\n",
    "    df.loc[minor_anomaly_indices, \"pressure\"] += np.random.normal(0, 3.0, size=num_minor_anomalies)\n",
    "    \n",
    "    # 5. Maintenance effects\n",
    "    maintenance_events = [3000, 10000, 20000, 45000, 75000]\n",
    "    maintenance_events = [i for i in maintenance_events if i < time_steps]\n",
    "    \n",
    "    for event in maintenance_events:\n",
    "        if event + 24*3 <= time_steps:  # 3 days of improved readings\n",
    "            recovery_indices = range(event, event + 24*3)\n",
    "            df.loc[recovery_indices, \"vibration\"] = df.loc[recovery_indices, \"vibration\"] * 0.8\n",
    "            df.loc[recovery_indices, \"temperature\"] = df.loc[recovery_indices, \"temperature\"] * 0.95\n",
    "            df.loc[recovery_indices, \"pressure\"] = np.random.normal(loc=30, scale=1.0, size=len(recovery_indices))\n",
    "    \n",
    "    # 6. Cyclical load patterns (daily variations)\n",
    "    for i in range(0, time_steps, 24):  # Daily cycle\n",
    "        if i + 8 <= time_steps:  # Night hours - lower usage\n",
    "            night_indices = range(i, i + 8)\n",
    "            df.loc[night_indices, \"flow_rate\"] *= 0.8  # Lower flow rates at night\n",
    "            df.loc[night_indices, \"pressure\"] *= 0.9  # Lower pressure at night\n",
    "    \n",
    "    # 7. Correlated anomalies\n",
    "    correlated_anomaly_indices = np.random.choice(time_steps, size=50, replace=False)\n",
    "    for idx in correlated_anomaly_indices:\n",
    "        if idx < time_steps:\n",
    "            severity = np.random.uniform(0.5, 1.5)\n",
    "            df.loc[idx, \"vibration\"] += 0.2 * severity\n",
    "            df.loc[idx, \"temperature\"] += 3 * severity\n",
    "            df.loc[idx, \"pressure\"] -= 5 * severity\n",
    "            df.loc[idx, \"flow_rate\"] -= 15 * severity\n",
    "    \n",
    "    df.to_csv(filename, index=False)\n",
    "    return filename\n",
    "\n",
    "# Try with a lower number of data points first to ensure it works\n",
    "csv_file = generate_synthetic_pump_data(time_steps=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72adfc64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Pump MDP Analysis - 10000 rows total\n",
      "\n",
      "Dataframe Sample (first 5 rows):\n",
      "            timestamp  vibration  temperature   pressure  flow_rate     state  \\\n",
      "0 2025-01-01 00:00:00   0.224836    61.821505  27.626915  64.155424  Degraded   \n",
      "1 2025-01-01 01:00:00   0.193087    62.194501  27.509982  71.560115  Degraded   \n",
      "2 2025-01-01 02:00:00   0.232384    61.902619  25.314264  75.303773  Degraded   \n",
      "3 2025-01-01 03:00:00   0.276151    62.610418  28.043252  81.197351  Degraded   \n",
      "4 2025-01-01 04:00:00   0.188292    63.697179  24.317851  88.193299    Faulty   \n",
      "\n",
      "              best_action  \n",
      "0  Preventive Maintenance  \n",
      "1  Preventive Maintenance  \n",
      "2  Preventive Maintenance  \n",
      "3  Preventive Maintenance  \n",
      "4  Preventive Maintenance  \n",
      "\n",
      "State Distribution:\n",
      "state\n",
      "Healthy     4805\n",
      "Degraded    4437\n",
      "Faulty       758\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Action Distribution:\n",
      "best_action\n",
      "Preventive Maintenance    5195\n",
      "Do Nothing                4805\n",
      "Name: count, dtype: int64\n",
      "\n",
      "ðŸ§  Predictive Maintenance Summary:\n",
      "\n",
      "1. Most Frequent State: 'Healthy' (4805 occurrences, 48.0%)\n",
      "2. Recommended Action for that State: 'Do Nothing'\n",
      "3. State Distribution: \n",
      "   - Healthy: 4805 (48.0%)\n",
      "   - Degraded: 4437 (44.4%)\n",
      "   - Faulty: 758 (7.6%)\n",
      "4. State Values (Expected Long-term Reward): {'Healthy': -9.805587328003309, 'Degraded': -10.0, 'Faulty': -20.0}\n",
      "5. Optimal Policy: {'Healthy': 'Do Nothing', 'Degraded': 'Preventive Maintenance', 'Faulty': 'Preventive Maintenance'}\n",
      "6. Action Distribution: {'Preventive Maintenance': 5195, 'Do Nothing': 4805}\n",
      "7. State Transition Patterns: {'Healthy': {'Healthy': '61.5%', 'Degraded': '34.1%', 'Faulty': '4.4%'}, 'Degraded': {'Degraded': '54.1%', 'Healthy': '36.4%', 'Faulty': '9.5%'}, 'Faulty': {'Degraded': '52.5%', 'Healthy': '31.1%', 'Faulty': '16.4%'}}\n",
      "\n",
      "ðŸ“‹ Recommendations:\n",
      "- Set up real-time classification for sensor input into: Healthy, Degraded, or Faulty.\n",
      "- When pump is 'Degraded', perform Preventive Maintenance to avoid high repair costs.\n",
      "- Only use Corrective Maintenance for confirmed 'Faulty' state.\n",
      "- Schedule regular inspections every 20 time units based on transition patterns.\n",
      "- Integrate this MDP policy into a monitoring system for automated decisions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "# Set the environment variable for the CSV file path\n",
    "\n",
    "# 2. Full MDP Pipeline\n",
    "def mdp_pipeline(csv_path, gamma=0.95):\n",
    "    df = pd.read_csv(csv_path, parse_dates=[\"timestamp\"])\n",
    "\n",
    "    # Step 1: Classify state\n",
    "    def classify_state(row):\n",
    "        if row[\"vibration\"] > 0.6 or row[\"temperature\"] > 65 or row[\"pressure\"] < 25:\n",
    "            return \"Faulty\"\n",
    "        elif row[\"vibration\"] > 0.3 or row[\"temperature\"] > 62 or row[\"pressure\"] < 28:\n",
    "            return \"Degraded\"\n",
    "        else:\n",
    "            return \"Healthy\"\n",
    "    df[\"state\"] = df.apply(classify_state, axis=1)\n",
    "\n",
    "    # Step 2: Define rewards and actions\n",
    "    states = [\"Healthy\", \"Degraded\", \"Faulty\"]\n",
    "    actions = [\"Do Nothing\", \"Preventive Maintenance\", \"Corrective Maintenance\"]\n",
    "    R = {\n",
    "        \"Healthy\": {\"Do Nothing\": 0, \"Preventive Maintenance\": -10, \"Corrective Maintenance\": -30},\n",
    "        \"Degraded\": {\"Do Nothing\": -5, \"Preventive Maintenance\": -10, \"Corrective Maintenance\": -30},\n",
    "        \"Faulty\": {\"Do Nothing\": -100, \"Preventive Maintenance\": -20, \"Corrective Maintenance\": -50},\n",
    "    }\n",
    "    df[\"best_action\"] = df[\"state\"].map(lambda x: \"Do Nothing\")  # Initial action\n",
    "\n",
    "    # Step 3: Count transitions\n",
    "    transition_counts = {\n",
    "        s: {a: {s1: 0 for s1 in states} for a in actions} for s in states\n",
    "    }\n",
    "    action_counts = {\n",
    "        s: {a: 0 for a in actions} for s in states\n",
    "    }\n",
    "\n",
    "    for t in range(len(df) - 1):\n",
    "        s, a, s1 = df.loc[t, \"state\"], df.loc[t, \"best_action\"], df.loc[t + 1, \"state\"]\n",
    "        transition_counts[s][a][s1] += 1\n",
    "        action_counts[s][a] += 1\n",
    "\n",
    "    # Step 4: Estimate transition probabilities\n",
    "    estimated_P = {\n",
    "        s: {\n",
    "            a: {\n",
    "                s1: transition_counts[s][a][s1] / action_counts[s][a]\n",
    "                if action_counts[s][a] > 0 else 0\n",
    "                for s1 in states\n",
    "            }\n",
    "            for a in actions\n",
    "        }\n",
    "        for s in states\n",
    "    }\n",
    "\n",
    "    # Step 5: Value Iteration\n",
    "    V = {s: 0 for s in states}\n",
    "    policy = {s: None for s in states}\n",
    "    for _ in range(100):\n",
    "        delta = 0\n",
    "        new_V = V.copy()\n",
    "        for s in states:\n",
    "            values = []\n",
    "            for a in actions:\n",
    "                expected = R[s][a] + gamma * sum(\n",
    "                    estimated_P[s][a][s1] * V[s1] for s1 in states\n",
    "                )\n",
    "                values.append(expected)\n",
    "            best_val = max(values)\n",
    "            delta = max(delta, abs(V[s] - best_val))\n",
    "            new_V[s] = best_val\n",
    "            policy[s] = actions[np.argmax(values)]\n",
    "        V = new_V\n",
    "        if delta < 1e-4:\n",
    "            break\n",
    "\n",
    "    df[\"best_action\"] = df[\"state\"].map(lambda x: policy[x])\n",
    "    return df, V, policy\n",
    "\n",
    "# 3. Interpret Result and Provide Guidelines\n",
    "def interpret_results(df, V, policy):\n",
    "    state_counts = df[\"state\"].value_counts().to_dict()\n",
    "    action_counts = df[\"best_action\"].value_counts().to_dict()\n",
    "    most_common_state = max(state_counts, key=state_counts.get)\n",
    "\n",
    "    # Calculate state percentages\n",
    "    total_states = sum(state_counts.values())\n",
    "    state_percentages = {s: (count/total_states)*100 for s, count in state_counts.items()}\n",
    "    \n",
    "    # Calculate transition probabilities between states - FIX for KEY ERROR\n",
    "    transitions = {}\n",
    "    for state in [\"Healthy\", \"Degraded\", \"Faulty\"]:\n",
    "        # Find rows of current state\n",
    "        state_indices = df[df[\"state\"] == state].index.tolist()\n",
    "        \n",
    "        # Get valid next indices (don't go past the end of the dataframe)\n",
    "        valid_next_indices = [i+1 for i in state_indices if i+1 < len(df)]\n",
    "        \n",
    "        if valid_next_indices:\n",
    "            # Get states at the valid next indices\n",
    "            next_states = df.loc[valid_next_indices, \"state\"].value_counts().to_dict()\n",
    "            total = sum(next_states.values())\n",
    "            transitions[state] = {next_state: f\"{(count/total)*100:.1f}%\" \n",
    "                                for next_state, count in next_states.items()}\n",
    "        else:\n",
    "            transitions[state] = {\"No transitions observed\": \"N/A\"}\n",
    "\n",
    "    summary = f\"\"\"\n",
    "ðŸ§  Predictive Maintenance Summary:\n",
    "\n",
    "1. Most Frequent State: '{most_common_state}' ({state_counts[most_common_state]} occurrences, {state_percentages[most_common_state]:.1f}%)\n",
    "2. Recommended Action for that State: '{policy[most_common_state]}'\n",
    "3. State Distribution: \n",
    "   - Healthy: {state_counts.get('Healthy', 0)} ({state_percentages.get('Healthy', 0):.1f}%)\n",
    "   - Degraded: {state_counts.get('Degraded', 0)} ({state_percentages.get('Degraded', 0):.1f}%)\n",
    "   - Faulty: {state_counts.get('Faulty', 0)} ({state_percentages.get('Faulty', 0):.1f}%)\n",
    "4. State Values (Expected Long-term Reward): {V}\n",
    "5. Optimal Policy: {policy}\n",
    "6. Action Distribution: {action_counts}\n",
    "7. State Transition Patterns: {transitions}\n",
    "\n",
    "ðŸ“‹ Recommendations:\n",
    "- Set up real-time classification for sensor input into: Healthy, Degraded, or Faulty.\n",
    "- When pump is 'Degraded', perform {policy.get('Degraded', 'Preventive Maintenance')} to avoid high repair costs.\n",
    "- Only use Corrective Maintenance for confirmed 'Faulty' state.\n",
    "- Schedule regular inspections every {len(df)//500} time units based on transition patterns.\n",
    "- Integrate this MDP policy into a monitoring system for automated decisions.\n",
    "\"\"\"\n",
    "    return summary\n",
    "\n",
    "# Execute full pipeline\n",
    "# Use the already generated CSV file\n",
    "csv_file = \"synthetic_pump_data.csv\"  # Use the file created by generate_synthetic_pump_data\n",
    "final_df, value_map, optimal_policy = mdp_pipeline(csv_file)\n",
    "summary_text = interpret_results(final_df, value_map, optimal_policy)\n",
    "\n",
    "# Display basic dataframe info and sample without ace_tools\n",
    "print(f\"Final Pump MDP Analysis - {len(final_df)} rows total\")\n",
    "print(\"\\nDataframe Sample (first 5 rows):\")\n",
    "print(final_df.head())\n",
    "\n",
    "print(\"\\nState Distribution:\")\n",
    "print(final_df[\"state\"].value_counts())\n",
    "\n",
    "print(\"\\nAction Distribution:\")\n",
    "print(final_df[\"best_action\"].value_counts())\n",
    "\n",
    "# Display the summary text\n",
    "print(summary_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d11fe7b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and processing pump data...\n",
      "\n",
      "===== Standard MDP Analysis =====\n",
      "Data points: 10000 rows\n",
      "State Distribution:\n",
      "state\n",
      "Healthy     4805\n",
      "Degraded    4437\n",
      "Faulty       758\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Optimal Policy:\n",
      "{'Healthy': 'Do Nothing', 'Degraded': 'Preventive Maintenance', 'Faulty': 'Preventive Maintenance'}\n",
      "\n",
      "===== Gemini-Powered Shift Analysis =====\n",
      "## Pump System Maintenance Report - Start of Shift (2025-01-09)\n",
      "\n",
      "**Date:** 2025-01-09\n",
      "**Prepared by:** Industrial Maintenance Engineer\n",
      "\n",
      "**1. Executive Summary:**\n",
      "\n",
      "The pump system is showing signs of significant degradation. While nearly half of the readings indicate a healthy state (48.05%), a substantial portion indicates a degraded state (44.37%). Alarmingly, 7.58% of the readings classify the system as faulty. Recent transitions from \"Healthy\" to \"Faulty\" provide insight into potential failure modes. Based on the Markov Decision Process (MDP) model, immediate action is required to prevent catastrophic failure and minimize downtime. The current policy and value function suggest proactive maintenance is more cost-effective than reactive repairs.\n",
      "\n",
      "**2. Anomaly Detection and Potential Causes:**\n",
      "\n",
      "*   **Overall State:** The high percentage of \"Degraded\" and \"Faulty\" readings relative to \"Healthy\" readings indicates a systemic problem requiring immediate attention. The trend is concerning.\n",
      "\n",
      "*   **State Transitions (Healthy to Faulty):** Analysis of transitions from \"Healthy\" to \"Faulty\" reveals critical insights into the potential causes of failure. Notable transitions and contributing metrics are:\n",
      "\n",
      "    *   **2025-01-01 19:00:00:** Moderate increase in Vibration (0.18), Elevated Temperature (65.51), and Elevated Pressure (37.16). This combination suggests potential bearing wear or pump cavitation.\n",
      "    *   **2025-01-04 10:00:00:** Significant increase in Vibration (0.27), Moderate Temperature (62.77) decrease, Significant decrease in Pressure (24.21), High Flow Rate (97.33). This could indicate a developing imbalance in the pump rotor or an obstruction causing pressure drop and increased flow demand.\n",
      "    *   **2025-01-05 07:00:00:** Vibration (0.19), Moderate Temperature (62.84) decrease, Significant decrease in Pressure (24.69), Flow Rate (84.15).  Similar to the 2025-01-04 transition, potential rotor imbalance or obstruction issue.\n",
      "    *   **2025-01-05 10:00:00:** High Vibration (0.39), Elevated Temperature (65.40), Moderate Pressure (31.15), Very High Flow Rate (110.67). This is the most severe transition, suggesting significant component degradation and high stress on the system.\n",
      "    *   **2025-01-08 21:00:00:** Vibration (0.19), Moderate Temperature (63.13) decrease, Significant decrease in Pressure (23.58), Very High Flow Rate (108.30). Similar to the other \"Faulty\" transitions, it indicates potential rotor imbalance or obstruction issue.\n",
      "\n",
      "*   **Timestamp Analysis:** The presence of faulty timestamp values in the early hours of 2025-01-01, as well as the high frequency of Healthy-to-Faulty transitions in the days following, suggests the underlying problem is rapidly progressing.\n",
      "\n",
      "**3. Immediate Actions Required (During This Shift):**\n",
      "\n",
      "1.  **Verification of Sensor Data:** Before initiating physical inspections, double-check the calibration and functionality of all sensors (vibration, temperature, pressure, and flow rate). Spurious sensor readings can lead to misdiagnosis.\n",
      "2.  **Physical Inspection:** Conduct a thorough physical inspection of the pump and its associated components. Pay close attention to:\n",
      "    *   **Bearing Condition:** Listen for unusual noises (grinding, squealing) that may indicate bearing wear. Check for excessive heat or vibration.\n",
      "    *   **Pump Cavitation:** Listen for cavitation noises. Inspect the pump housing for signs of damage.\n",
      "    *   **Rotor Balance:** Inspect the rotor for physical damage, debris buildup, or signs of imbalance.\n",
      "    *   **Pipe Obstruction:** Inspect the intake and discharge pipes for potential blockages or restrictions.\n",
      "3.  **Fluid Analysis:** Collect a sample of the pump fluid and analyze it for contaminants, viscosity, and other relevant properties. This can provide insights into wear and lubrication issues.\n",
      "4.  **Review Historical Data:** Compare the current sensor readings and state transitions with historical data to identify any long-term trends or anomalies.\n",
      "5.  **Implement Mitigation Strategy:** Based on findings, implement a strategy to avoid a complete failure (Reduce Flow, Shut Down).\n",
      "\n",
      "**4. Potential Maintenance Schedule:**\n",
      "\n",
      "Based on the data, a comprehensive maintenance schedule should be implemented urgently:\n",
      "\n",
      "*   **Immediate (This Shift):** Implement the immediate actions outlined in section 3.\n",
      "*   **Within 24 Hours:**\n",
      "    *   **Dynamic Balancing:** If rotor imbalance is suspected, schedule dynamic balancing of the pump rotor.\n",
      "    *   **Bearing Replacement:** If bearing wear is confirmed, order and schedule replacement of the bearings.\n",
      "    *   **Flushing System:** Schedule flushing of the pump fluid and replacement with fresh, clean fluid.\n",
      "    *   **System Flush**: A comprehensive flushing procedure of the pump system should be implemented to remove any contaminants.\n",
      "*   **Within 1 Week:**\n",
      "    *   **Pump Overhaul:** Plan a comprehensive pump overhaul, including inspection and replacement of all critical components.\n",
      "    *   **Root Cause Analysis:** Conduct a thorough root cause analysis to identify the underlying factors contributing to the pump's degradation. Implement corrective actions to prevent future failures.\n",
      "\n",
      "**5. Cost-Benefit Analysis (Maintenance Now vs. Waiting):**\n",
      "\n",
      "The MDP model's value function highlights the significant cost difference between addressing issues in the \"Degraded\" or \"Faulty\" states versus maintaining the system in a \"Healthy\" state. Waiting for a complete failure carries a substantial cost penalty (-20.0 value).\n",
      "\n",
      "**Cost of Preventive Maintenance (Now):**\n",
      "\n",
      "*   Component Replacement (bearings, seals, fluid)\n",
      "*   Labor Costs (inspection, repair, balancing)\n",
      "*   Potential Minor Downtime\n",
      "\n",
      "**Cost of Waiting (and Potentially Catastrophic Failure):**\n",
      "\n",
      "*   Significantly higher component replacement costs (potentially including the entire pump)\n",
      "*   Increased Labor Costs (emergency repair, overtime)\n",
      "*   Significant Downtime (lost production, potential damage to other equipment)\n",
      "*   Safety Risks (potential for accidents due to equipment failure)\n",
      "\n",
      "**Conclusion:**\n",
      "\n",
      "Based on the MDP model, the severity of the current state, and the cost analysis, **performing proactive maintenance now is significantly more cost-effective and safer than waiting for a catastrophic failure.** Deferring maintenance will likely result in higher costs, increased downtime, and potential safety risks. The recommendation is to prioritize the immediate actions outlined in Section 3 and implement the recommended maintenance schedule as soon as possible.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "# Set the environment variable for the CSV file path\n",
    "\n",
    "# 2. Full MDP Pipeline\n",
    "def mdp_pipeline(csv_path, gamma=0.95):\n",
    "    df = pd.read_csv(csv_path, parse_dates=[\"timestamp\"])\n",
    "\n",
    "    # Step 1: Classify state\n",
    "    def classify_state(row):\n",
    "        if row[\"vibration\"] > 0.6 or row[\"temperature\"] > 65 or row[\"pressure\"] < 25:\n",
    "            return \"Faulty\"\n",
    "        elif row[\"vibration\"] > 0.3 or row[\"temperature\"] > 62 or row[\"pressure\"] < 28:\n",
    "            return \"Degraded\"\n",
    "        else:\n",
    "            return \"Healthy\"\n",
    "    df[\"state\"] = df.apply(classify_state, axis=1)\n",
    "\n",
    "    # Step 2: Define rewards and actions\n",
    "    states = [\"Healthy\", \"Degraded\", \"Faulty\"]\n",
    "    actions = [\"Do Nothing\", \"Preventive Maintenance\", \"Corrective Maintenance\"]\n",
    "    R = {\n",
    "        \"Healthy\": {\"Do Nothing\": 0, \"Preventive Maintenance\": -10, \"Corrective Maintenance\": -30},\n",
    "        \"Degraded\": {\"Do Nothing\": -5, \"Preventive Maintenance\": -10, \"Corrective Maintenance\": -30},\n",
    "        \"Faulty\": {\"Do Nothing\": -100, \"Preventive Maintenance\": -20, \"Corrective Maintenance\": -50},\n",
    "    }\n",
    "    df[\"best_action\"] = df[\"state\"].map(lambda x: \"Do Nothing\")  # Initial action\n",
    "\n",
    "    # Step 3: Count transitions\n",
    "    transition_counts = {\n",
    "        s: {a: {s1: 0 for s1 in states} for a in actions} for s in states\n",
    "    }\n",
    "    action_counts = {\n",
    "        s: {a: 0 for a in actions} for s in states\n",
    "    }\n",
    "\n",
    "    for t in range(len(df) - 1):\n",
    "        s, a, s1 = df.loc[t, \"state\"], df.loc[t, \"best_action\"], df.loc[t + 1, \"state\"]\n",
    "        transition_counts[s][a][s1] += 1\n",
    "        action_counts[s][a] += 1\n",
    "\n",
    "    # Step 4: Estimate transition probabilities\n",
    "    estimated_P = {\n",
    "        s: {\n",
    "            a: {\n",
    "                s1: transition_counts[s][a][s1] / action_counts[s][a]\n",
    "                if action_counts[s][a] > 0 else 0\n",
    "                for s1 in states\n",
    "            }\n",
    "            for a in actions\n",
    "        }\n",
    "        for s in states\n",
    "    }\n",
    "\n",
    "    # Step 5: Value Iteration\n",
    "    V = {s: 0 for s in states}\n",
    "    policy = {s: None for s in states}\n",
    "    for _ in range(100):\n",
    "        delta = 0\n",
    "        new_V = V.copy()\n",
    "        for s in states:\n",
    "            values = []\n",
    "            for a in actions:\n",
    "                expected = R[s][a] + gamma * sum(\n",
    "                    estimated_P[s][a][s1] * V[s1] for s1 in states\n",
    "                )\n",
    "                values.append(expected)\n",
    "            best_val = max(values)\n",
    "            delta = max(delta, abs(V[s] - best_val))\n",
    "            new_V[s] = best_val\n",
    "            policy[s] = actions[np.argmax(values)]\n",
    "        V = new_V\n",
    "        if delta < 1e-4:\n",
    "            break\n",
    "\n",
    "    df[\"best_action\"] = df[\"state\"].map(lambda x: policy[x])\n",
    "    return df, V, policy\n",
    "\n",
    "# Configure Gemini API with your key and use Gemini 1.5 Flash model\n",
    "def configure_gemini_api():\n",
    "    # Load API key from .env using dotenv\n",
    "    api_key = os.environ.get(\"GEMINI_API_KEY\")\n",
    "    genai.configure(api_key=api_key)\n",
    "    # Use Gemini 1.5 Flash model (the latest fast model as of 2024)\n",
    "    return genai.GenerativeModel('models/gemini-2.0-flash')\n",
    "\n",
    "# Analyze pump data with Gemini API\n",
    "def gemini_analysis(df, V, policy, shift_start_time=None):\n",
    "    # Extract key information for analysis\n",
    "    state_counts = df[\"state\"].value_counts().to_dict()\n",
    "    total_states = sum(state_counts.values())\n",
    "    state_percentages = {s: (count/total_states)*100 for s, count in state_counts.items()}\n",
    "    \n",
    "    # Find anomaly timestamps\n",
    "    faulty_indices = df[df[\"state\"] == \"Faulty\"].index.tolist()\n",
    "    degraded_indices = df[df[\"state\"] == \"Degraded\"].index.tolist()\n",
    "    \n",
    "    # Get timestamps for the first few anomalies\n",
    "    faulty_timestamps = []\n",
    "    degraded_timestamps = []\n",
    "    \n",
    "    if faulty_indices:\n",
    "        faulty_timestamps = df.loc[faulty_indices[:5], \"timestamp\"].tolist()\n",
    "    \n",
    "    if degraded_indices:\n",
    "        degraded_timestamps = df.loc[degraded_indices[:5], \"timestamp\"].tolist()\n",
    "    \n",
    "    # Find trends and patterns\n",
    "    # Detect major transitions from healthy to faulty\n",
    "    state_transitions = []\n",
    "    for i in range(1, len(df)):\n",
    "        if df.loc[i-1, \"state\"] == \"Healthy\" and df.loc[i, \"state\"] == \"Faulty\":\n",
    "            state_transitions.append({\n",
    "                \"from\": \"Healthy\",\n",
    "                \"to\": \"Faulty\",\n",
    "                \"timestamp\": df.loc[i, \"timestamp\"],\n",
    "                \"metrics\": {\n",
    "                    \"vibration\": df.loc[i, \"vibration\"],\n",
    "                    \"temperature\": df.loc[i, \"temperature\"],\n",
    "                    \"pressure\": df.loc[i, \"pressure\"],\n",
    "                    \"flow_rate\": df.loc[i, \"flow_rate\"],\n",
    "                }\n",
    "            })\n",
    "    \n",
    "    # Get subset of data for hourly summary\n",
    "    if shift_start_time:\n",
    "        # Convert string to datetime if needed\n",
    "        if isinstance(shift_start_time, str):\n",
    "            shift_start_time = datetime.fromisoformat(shift_start_time)\n",
    "        \n",
    "        # Filter to the last 8 hours (typical shift length)\n",
    "        shift_data = df[df[\"timestamp\"] >= shift_start_time]\n",
    "        shift_summary = {\n",
    "            \"start_time\": shift_start_time,\n",
    "            \"total_readings\": len(shift_data),\n",
    "            \"healthy_count\": len(shift_data[shift_data[\"state\"] == \"Healthy\"]),\n",
    "            \"degraded_count\": len(shift_data[shift_data[\"state\"] == \"Degraded\"]),\n",
    "            \"faulty_count\": len(shift_data[shift_data[\"state\"] == \"Faulty\"]),\n",
    "        }\n",
    "    else:\n",
    "        shift_summary = None\n",
    "    \n",
    "    # Prepare analysis prompt for Gemini\n",
    "    analysis_context = {\n",
    "        \"state_percentages\": state_percentages,\n",
    "        \"state_transitions\": state_transitions[:5],  # Send only first 5 transitions\n",
    "        \"faulty_timestamps\": faulty_timestamps,\n",
    "        \"degraded_timestamps\": degraded_timestamps,\n",
    "        \"policy\": policy,\n",
    "        \"value_function\": V,\n",
    "        \"shift_summary\": shift_summary\n",
    "    }\n",
    "    \n",
    "    model = configure_gemini_api()\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    You are an experienced industrial maintenance engineer analyzing pump sensor data at the beginning of your shift.\n",
    "    \n",
    "    The data has been processed through a Markov Decision Process model and classified into three states:\n",
    "    - Healthy: Normal operating conditions\n",
    "    - Degraded: Early warning signs, pump still operational\n",
    "    - Faulty: Critical issues requiring immediate attention\n",
    "    \n",
    "    Here's the current state of the pump system:\n",
    "    {json.dumps(analysis_context, indent=2, default=str)}\n",
    "    \n",
    "    As the engineer starting your shift, please provide:\n",
    "    1. A brief summary of the pump's current condition\n",
    "    2. Specific times when anomalies were detected and what likely caused them\n",
    "    3. Recommendations for immediate actions needed during this shift\n",
    "    4. Potential maintenance schedule based on the detected patterns\n",
    "    5. Cost-benefit analysis of performing maintenance now vs. waiting\n",
    "    \n",
    "    Format your response as a professional maintenance report that I can share with my team.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = model.generate_content(prompt)\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        return f\"Error generating analysis: {str(e)}\\n\\nPlease ensure your API key is valid and you have proper permissions.\"\n",
    "\n",
    "# Execute full pipeline with Gemini analysis\n",
    "def run_maintenance_analysis(csv_path, shift_start=None):\n",
    "    print(\"Loading and processing pump data...\")\n",
    "    df, value_map, optimal_policy = mdp_pipeline(csv_path)\n",
    "    \n",
    "    print(\"\\n===== Standard MDP Analysis =====\")\n",
    "    print(f\"Data points: {len(df)} rows\")\n",
    "    print(\"State Distribution:\")\n",
    "    print(df[\"state\"].value_counts())\n",
    "    print(\"\\nOptimal Policy:\")\n",
    "    print(optimal_policy)\n",
    "    \n",
    "    print(\"\\n===== Gemini-Powered Shift Analysis =====\")\n",
    "    gemini_report = gemini_analysis(df, value_map, optimal_policy, shift_start)\n",
    "    print(gemini_report)\n",
    "    \n",
    "    return df, gemini_report\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # To simulate an engineer starting their shift\n",
    "    shift_start_time = \"2025-01-04T06:00:00\"  # Example shift start time\n",
    "    \n",
    "    # Use the generated CSV file\n",
    "    csv_file = \"synthetic_pump_data.csv\"\n",
    "    if not os.path.exists(csv_file):\n",
    "        from predictive_maintenance import generate_synthetic_pump_data\n",
    "        csv_file = generate_synthetic_pump_data(time_steps=10000)\n",
    "    \n",
    "    # Run the full analysis pipeline\n",
    "    final_df, engineer_report = run_maintenance_analysis(csv_file, shift_start_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dogo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
